{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_data = iris.data\n",
    "iris_features = iris.feature_names\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume a mixture model with three Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(iris.target_names)\n",
    "iris_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(iris_data,iris.target,test_size=0.33,random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_data)\n",
    "#test_size = 150 - train_size\n",
    "test_size = len(test_data)\n",
    "train_class_cnt = [0,0,0]\n",
    "test_class_cnt = [0,0,0]\n",
    "est_prior = [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_mean = [[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
    "est_covar = [[[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]],[[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]],[[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]]\n",
    "\n",
    "for i in range(train_size):\n",
    "    est_mean[train_labels[i]] += train_data[i]\n",
    "    train_class_cnt[train_labels[i]] += 1\n",
    "\n",
    "for i in range(train_size):\n",
    "    mat = np.matrix(train_data[i]-est_mean[train_labels[i]])\n",
    "    est_covar[train_labels[i]] += np.matmul(mat.transpose(),mat)\n",
    "\n",
    "for i in range(3):\n",
    "    est_mean[i] /= train_class_cnt[i]\n",
    "    est_covar[i] /= train_class_cnt[i]\n",
    "\n",
    "for i in range(test_size):\n",
    "    test_class_cnt[test_labels[i]] += 1\n",
    "\n",
    "for i in range(3):    \n",
    "    est_prior[i] = (1/train_size)*train_class_cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 37, 31]\n",
      "[array([4.965625, 3.40625 , 1.4625  , 0.25    ]), array([5.97567568, 2.77027027, 4.25945946, 1.31891892]), array([6.5483871 , 2.9483871 , 5.50645161, 1.96451613])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[matrix([[23695.9209375, 16254.61625  ,  6979.02375  ,  1193.00125  ],\n",
       "         [16254.61625  , 11150.190625 ,  4787.3846875,   818.3590625],\n",
       "         [ 6979.02375  ,  4787.3846875,  2055.52     ,   351.3740625],\n",
       "         [ 1193.00125  ,   818.3590625,   351.3740625,    60.075    ]]),\n",
       " matrix([[46278.72432432, 21454.38      , 32987.45162162, 10214.38918919],\n",
       "         [21454.38      ,  9946.12324324, 15292.69783784,  4735.32054054],\n",
       "         [32987.45162162, 15292.69783784, 23513.54378378,  7280.84648649],\n",
       "         [10214.38918919,  4735.32054054,  7280.84648649,  2254.49243243]]),\n",
       " matrix([[38593.70258065, 17376.58129032, 32452.90290323, 11578.0283871 ],\n",
       "         [17376.58129032,  7823.80129032, 14611.72548387,  5212.97774194],\n",
       "         [32452.90290323, 14611.72548387, 27289.27677419,  9735.82322581],\n",
       "         [11578.0283871 ,  5212.97774194,  9735.82322581,  3473.4516129 ]])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_class_cnt)\n",
    "print(est_mean)\n",
    "est_covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[36669.8705, 18526.338 , 24499.0446,  7750.2732],\n",
       "        [18526.338 ,  9673.505 , 11719.8962,  3629.9666],\n",
       "        [24499.0446, 11719.8962, 17817.4534,  5824.4581],\n",
       "        [ 7750.2732,  3629.9666,  5824.4581,  1930.1562]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_covar = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
    "\n",
    "for i in range(3):\n",
    "    common_covar += (train_class_cnt[i]/train_size)*est_covar[i]\n",
    "\n",
    "common_covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equal priors and variances\n",
    "def makePred_eq_priors_eq_var(trainData,testData,est_mean):\n",
    "    pred_train = [None]*train_size\n",
    "    pred_test = [None]*test_size\n",
    "\n",
    "    for i in range(train_size):\n",
    "        if i < test_size:\n",
    "            mat1 = np.matrix(testData[i])\n",
    "            res = [est_mean[0]*mat1.transpose() - np.linalg.norm(est_mean[0])/2, est_mean[1]*mat1.transpose() - np.linalg.norm(est_mean[1])/2, est_mean[2]*mat1.transpose() - np.linalg.norm(est_mean[2])/2]\n",
    "            res = res.index(max(list(res)))\n",
    "            pred_test[i] = res\n",
    "        mat1 = np.matrix(trainData[i])\n",
    "        res = [est_mean[0]*mat1.transpose() - np.linalg.norm(est_mean[0])/2, est_mean[1]*mat1.transpose() - np.linalg.norm(est_mean[1])/2, est_mean[2]*mat1.transpose() - np.linalg.norm(est_mean[2])/2]\n",
    "        res = res.index(max(list(res)))\n",
    "        pred_train[i] = res\n",
    "    return pred_train, pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAccuracy(trainLabel_DIST1,count_train,pred_train,testLabel_DIST1,count_test,pred_test):\n",
    "    train_accuracy = [0,0,0]\n",
    "    test_accuracy = [0,0,0]\n",
    "    for i in range(train_size):\n",
    "        if i < test_size:\n",
    "            if testLabel_DIST1[i] == pred_test[i]:\n",
    "                test_accuracy[testLabel_DIST1[i]] += 1\n",
    "        if trainLabel_DIST1[i] == pred_train[i]:\n",
    "            train_accuracy[trainLabel_DIST1[i]] += 1\n",
    "\n",
    "    for i in range(3):\n",
    "        train_accuracy[i] /= count_train[i]\n",
    "        test_accuracy[i] /= count_test[i]\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, 0.0, 1.0], [0.0, 0.0, 1.0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train, pred_test = makePred_eq_priors_eq_var(train_data,test_data,est_mean)\n",
    "accr1 = calcAccuracy(train_labels,train_class_cnt,pred_train,test_labels,test_class_cnt,pred_test)\n",
    "accr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated priors and variances\n",
    "# can improve using the associativity of matrix multiplication\n",
    "def makePred_est_priors_est_var(trainData,testData,est_mean,est_covar,est_prior):\n",
    "    pred_train = [None]*train_size\n",
    "    pred_test = [None]*test_size\n",
    "\n",
    "    for i in range(train_size):\n",
    "        m_0 = np.matrix(est_mean[0])\n",
    "        m_1 = np.matrix(est_mean[1])\n",
    "        m_2 = np.matrix(est_mean[2])\n",
    "        S_0 = np.matrix(est_covar[0])\n",
    "        S_1 = np.matrix(est_covar[1])\n",
    "        S_2 = np.matrix(est_covar[2])\n",
    "        if i < test_size:\n",
    "            mat1 = np.matrix(testData[i])\n",
    "            r1 = np.matmul(np.matmul(mat1,np.linalg.inv(S_0)),mat1.transpose())\n",
    "            r2 = 2*np.matmul(np.matmul(mat1,np.linalg.inv(S_0)),m_0.transpose())\n",
    "            r3 = np.matmul(np.matmul(m_0,np.linalg.inv(S_0)),m_0.transpose())\n",
    "            r4 = np.matmul(np.matmul(mat1,np.linalg.inv(S_1)),mat1.transpose())\n",
    "            r5 = 2*np.matmul(np.matmul(mat1,np.linalg.inv(S_1)),m_1.transpose())\n",
    "            r6 = np.matmul(np.matmul(m_1,np.linalg.inv(S_1)),m_1.transpose())\n",
    "            r7 = np.matmul(np.matmul(mat1,np.linalg.inv(S_2)),mat1.transpose())\n",
    "            r8 = 2*np.matmul(np.matmul(mat1,np.linalg.inv(S_2)),m_2.transpose())\n",
    "            r9 = np.matmul(np.matmul(m_2,np.linalg.inv(S_2)),m_2.transpose())\n",
    "            \n",
    "            res = [-np.log(np.linalg.det(S_0))/2 - (r1-r2+r3)/2 + np.log(est_prior[0]),\n",
    "                   -np.log(np.linalg.det(S_1))/2 - (r4-r5+r6)/2 + np.log(est_prior[1]),\n",
    "                   -np.log(np.linalg.det(S_2))/2 - (r7-r8+r9)/2 + np.log(est_prior[2])]\n",
    "            res = res.index(max(list(res)))\n",
    "            pred_test[i] = res\n",
    "            \n",
    "        mat1 = np.matrix(trainData[i])\n",
    "        r1 = np.matmul(np.matmul(mat1,np.linalg.inv(S_0)),mat1.transpose())\n",
    "        r2 = 2*np.matmul(np.matmul(mat1,np.linalg.inv(S_0)),m_0.transpose())\n",
    "        r3 = np.matmul(np.matmul(m_0,np.linalg.inv(S_0)),m_0.transpose())\n",
    "        r4 = np.matmul(np.matmul(mat1,np.linalg.inv(S_1)),mat1.transpose())\n",
    "        r5 = 2*np.matmul(np.matmul(mat1,np.linalg.inv(S_1)),m_1.transpose())\n",
    "        r6 = np.matmul(np.matmul(m_1,np.linalg.inv(S_1)),m_1.transpose())\n",
    "        r7 = np.matmul(np.matmul(mat1,np.linalg.inv(S_2)),mat1.transpose())\n",
    "        r8 = 2*np.matmul(np.matmul(mat1,np.linalg.inv(S_2)),m_2.transpose())\n",
    "        r9 = np.matmul(np.matmul(m_2,np.linalg.inv(S_2)),m_2.transpose())\n",
    "        \n",
    "        res = [-np.log(np.linalg.det(S_0))/2 - (r1-r2+r3)/2 + np.log(est_prior[0]),\n",
    "               -np.log(np.linalg.det(S_1))/2 - (r4-r5+r6)/2 + np.log(est_prior[1]),\n",
    "               -np.log(np.linalg.det(S_2))/2 - (r7-r8+r9)/2 + np.log(est_prior[2])]\n",
    "        res = res.index(max(list(res)))\n",
    "        pred_train[i] = res\n",
    "    return pred_train, pred_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.918918918918919, 0.967741935483871], [1.0, 0.9230769230769231, 1.0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train, pred_test = makePred_est_priors_est_var(train_data,test_data,est_mean,est_covar,est_prior)\n",
    "accr2 = calcAccuracy(train_labels,train_class_cnt,pred_train,test_labels,test_class_cnt,pred_test)\n",
    "accr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using common covariance and estimated priors\n",
    "def makePred_common_covar_est_prior(trainData,testData,est_mean,com_covar,est_prior):\n",
    "    pred_train = [None]*train_size\n",
    "    pred_test = [None]*test_size\n",
    "\n",
    "    for i in range(train_size):\n",
    "        m_0 = np.matrix(est_mean[0])\n",
    "        m_1 = np.matrix(est_mean[1])\n",
    "        m_2 = np.matrix(est_mean[2])\n",
    "        S = np.matrix(com_covar)\n",
    "        if i < test_size:\n",
    "            mat1 = np.matrix(testData[i])\n",
    "            r2 = 2*np.matmul(np.matmul(mat1,np.linalg.inv(S)),m_0.transpose())\n",
    "            r3 = np.matmul(np.matmul(m_0,np.linalg.inv(S)),m_0.transpose())\n",
    "            r5 = 2*np.matmul(np.matmul(mat1,np.linalg.inv(S)),m_1.transpose())\n",
    "            r6 = np.matmul(np.matmul(m_1,np.linalg.inv(S)),m_1.transpose())\n",
    "            r8 = 2*np.matmul(np.matmul(mat1,np.linalg.inv(S)),m_2.transpose())\n",
    "            r9 = np.matmul(np.matmul(m_2,np.linalg.inv(S)),m_2.transpose())\n",
    "        \n",
    "            \n",
    "            res = [-(-r2+r3)/2 + np.log(est_prior[0]),\n",
    "                   -(-r5+r6)/2 + np.log(est_prior[1]),\n",
    "                   -(-r8+r9)/2 + np.log(est_prior[2])]\n",
    "            res = res.index(max(list(res)))\n",
    "            pred_test[i] = res\n",
    "            \n",
    "        mat1 = np.matrix(trainData[i])\n",
    "        r2 = 2*np.matmul(np.matmul(mat1,np.linalg.inv(S)),m_0.transpose())\n",
    "        r3 = np.matmul(np.matmul(m_0,np.linalg.inv(S)),m_0.transpose())\n",
    "        r5 = 2*np.matmul(np.matmul(mat1,np.linalg.inv(S)),m_1.transpose())\n",
    "        r6 = np.matmul(np.matmul(m_1,np.linalg.inv(S)),m_1.transpose())\n",
    "        r8 = 2*np.matmul(np.matmul(mat1,np.linalg.inv(S)),m_2.transpose())\n",
    "        r9 = np.matmul(np.matmul(m_2,np.linalg.inv(S)),m_2.transpose())\n",
    "        res = [-(-r2+r3)/2 + np.log(est_prior[0]),\n",
    "               -(-r5+r6)/2 + np.log(est_prior[1]),\n",
    "               -(-r8+r9)/2 + np.log(est_prior[2])]\n",
    "        res = res.index(max(list(res)))\n",
    "        pred_train[i] = res\n",
    "    return pred_train, pred_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, 1.0, 0.0], [0.0, 1.0, 0.0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train, pred_test = makePred_common_covar_est_prior(train_data,test_data,est_mean,common_covar,est_prior)\n",
    "accr3 = calcAccuracy(train_labels,train_class_cnt,pred_train,test_labels,test_class_cnt,pred_test)\n",
    "accr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equal variances est. priors\n",
    "def makePred_est_priors_eq_Allvar(trainData,testData,est_mean,var,est_prior):\n",
    "    pred_train = [None]*train_size\n",
    "    pred_test = [None]*test_size\n",
    "    mean0 = np.matrix(est_mean[0])\n",
    "    mean1 = np.matrix(est_mean[1])\n",
    "    mean2 = np.matrix(est_mean[2])\n",
    "\n",
    "    for i in range(train_size):\n",
    "        if i < test_size:\n",
    "            mat1 = np.matrix(testData[i])\n",
    "            res = [-np.linalg.norm(mat1-mean0)/(2*var) + np.log(est_prior[0]), \n",
    "                   -np.linalg.norm(mat1-mean1)/(2*var) + np.log(est_prior[1]),\n",
    "                   -np.linalg.norm(mat1-mean2)/(2*var) + np.log(est_prior[2])]\n",
    "            res = res.index(max(list(res)))\n",
    "            pred_test[i] = res\n",
    "        mat1 = np.matrix(trainData[i])\n",
    "        res = [-np.linalg.norm(mat1-mean0)/(2*var)+np.log(est_prior[0]), \n",
    "               -np.linalg.norm(mat1-mean1)/(2*var) + np.log(est_prior[1]),\n",
    "               -np.linalg.norm(mat1-mean2)/(2*var) + np.log(est_prior[2])]\n",
    "        res = res.index(max(list(res)))\n",
    "        pred_train[i] = res\n",
    "    return pred_train, pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, 1.0, 0.0], [0.0, 1.0, 0.0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.power(np.linalg.det(np.matrix(common_covar)),1/2)\n",
    "pred_train, pred_test = makePred_est_priors_eq_Allvar(train_data,test_data,est_mean,s,est_prior)\n",
    "accr4 = calcAccuracy(train_labels,train_class_cnt,pred_train,test_labels,test_class_cnt,pred_test)\n",
    "accr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive-Bayes Classifier\n",
    "def makePred_naive_bayes(trainData,testData,est_mean,est_covar,est_prior):\n",
    "    pred_train = [None]*train_size\n",
    "    pred_test = [None]*test_size\n",
    "\n",
    "    for i in range(train_size):\n",
    "        if i < test_size:\n",
    "            res = [0,0,0]\n",
    "            for j in range(3):\n",
    "                tmp = 0\n",
    "                for k in range(4):\n",
    "                    tmp += np.power((testData[i][k]-est_mean[j][k]),2)/est_covar[k,k]\n",
    "                res[j] += -tmp/2 + np.log(est_prior[j])\n",
    "            res = res.index(max(list(res)))\n",
    "            pred_test[i] = res\n",
    "            \n",
    "        res = [0,0,0]\n",
    "        for j in range(3):\n",
    "            tmp = 0\n",
    "            for k in range(4):\n",
    "                tmp += np.power((trainData[i][k]-est_mean[j][k]),2)/est_covar[k,k]\n",
    "            res[j] += -tmp/2 + np.log(est_prior[j])\n",
    "        res = res.index(max(list(res)))\n",
    "        pred_train[i] = res\n",
    "    return pred_train, pred_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, 1.0, 0.0], [0.0, 1.0, 0.0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train, pred_test = makePred_naive_bayes(train_data,test_data,est_mean,common_covar,est_prior)\n",
    "accr5 = calcAccuracy(train_labels,train_class_cnt,pred_train,test_labels,test_class_cnt,pred_test)\n",
    "accr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_covar_est_prior_test</th>\n",
       "      <th>common_covar_est_prior_train</th>\n",
       "      <th>eq_priors_eq_var_test</th>\n",
       "      <th>eq_priors_eq_var_train</th>\n",
       "      <th>est_priors_eq_Allvar_test</th>\n",
       "      <th>est_priors_eq_Allvar_train</th>\n",
       "      <th>est_priors_est_var_test</th>\n",
       "      <th>est_priors_est_var_train</th>\n",
       "      <th>naive_bayes_test</th>\n",
       "      <th>naive_bayes_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   common_covar_est_prior_test  common_covar_est_prior_train  \\\n",
       "0                          0.0                           0.0   \n",
       "1                          1.0                           1.0   \n",
       "2                          0.0                           0.0   \n",
       "\n",
       "   eq_priors_eq_var_test  eq_priors_eq_var_train  est_priors_eq_Allvar_test  \\\n",
       "0                    0.0                     0.0                        0.0   \n",
       "1                    0.0                     0.0                        1.0   \n",
       "2                    1.0                     1.0                        0.0   \n",
       "\n",
       "   est_priors_eq_Allvar_train  est_priors_est_var_test  \\\n",
       "0                         0.0                 1.000000   \n",
       "1                         1.0                 0.923077   \n",
       "2                         0.0                 1.000000   \n",
       "\n",
       "   est_priors_est_var_train  naive_bayes_test  naive_bayes_train  \n",
       "0                  1.000000               0.0                0.0  \n",
       "1                  0.918919               1.0                1.0  \n",
       "2                  0.967742               0.0                0.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_table = pd.DataFrame({\"naive_bayes_train\":accr5[0],\n",
    "                          \"naive_bayes_test\": accr5[1],\n",
    "                          \"est_priors_eq_Allvar_train\":accr4[0],\n",
    "                          \"est_priors_eq_Allvar_test\": accr4[1],\n",
    "                          \"common_covar_est_prior_train\":accr3[0],\n",
    "                          \"common_covar_est_prior_test\": accr3[1],\n",
    "                          \"est_priors_est_var_train\":accr2[0],\n",
    "                          \"est_priors_est_var_test\": accr2[1],\n",
    "                          \"eq_priors_eq_var_train\":accr1[0],\n",
    "                          \"eq_priors_eq_var_test\": accr1[1]})\n",
    "\n",
    "#res_table.style.set_properties(**{'number-align': 'left'})\n",
    "\n",
    "res_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
