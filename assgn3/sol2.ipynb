{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randint\n",
    "from scipy.linalg import eigh\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.75</td>\n",
       "      <td>22.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.80</td>\n",
       "      <td>22.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.55</td>\n",
       "      <td>21.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.70</td>\n",
       "      <td>20.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.90</td>\n",
       "      <td>19.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26.80</td>\n",
       "      <td>19.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28.35</td>\n",
       "      <td>18.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30.40</td>\n",
       "      <td>17.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.25</td>\n",
       "      <td>16.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29.05</td>\n",
       "      <td>16.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27.15</td>\n",
       "      <td>14.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28.20</td>\n",
       "      <td>13.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30.35</td>\n",
       "      <td>13.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27.25</td>\n",
       "      <td>11.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29.45</td>\n",
       "      <td>12.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31.55</td>\n",
       "      <td>12.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33.05</td>\n",
       "      <td>10.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29.95</td>\n",
       "      <td>9.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28.00</td>\n",
       "      <td>9.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27.15</td>\n",
       "      <td>7.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>29.15</td>\n",
       "      <td>8.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>31.95</td>\n",
       "      <td>8.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>34.70</td>\n",
       "      <td>8.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34.80</td>\n",
       "      <td>12.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36.30</td>\n",
       "      <td>15.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>36.60</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38.70</td>\n",
       "      <td>14.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>40.30</td>\n",
       "      <td>15.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>42.25</td>\n",
       "      <td>14.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>40.70</td>\n",
       "      <td>12.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>20.25</td>\n",
       "      <td>7.05</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>19.55</td>\n",
       "      <td>7.05</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>19.05</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>18.35</td>\n",
       "      <td>7.60</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>17.85</td>\n",
       "      <td>7.30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>18.30</td>\n",
       "      <td>7.10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>18.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>19.60</td>\n",
       "      <td>6.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>20.15</td>\n",
       "      <td>6.45</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>18.80</td>\n",
       "      <td>6.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>18.35</td>\n",
       "      <td>6.55</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>17.65</td>\n",
       "      <td>6.55</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>17.25</td>\n",
       "      <td>6.90</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>17.95</td>\n",
       "      <td>6.20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>17.45</td>\n",
       "      <td>9.85</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>17.20</td>\n",
       "      <td>9.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>17.00</td>\n",
       "      <td>9.60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>17.00</td>\n",
       "      <td>10.05</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>16.45</td>\n",
       "      <td>10.10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>16.50</td>\n",
       "      <td>9.80</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>16.60</td>\n",
       "      <td>9.45</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>16.60</td>\n",
       "      <td>9.05</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>15.90</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>16.05</td>\n",
       "      <td>9.35</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>16.05</td>\n",
       "      <td>9.65</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>15.85</td>\n",
       "      <td>9.95</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15.35</td>\n",
       "      <td>9.90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15.60</td>\n",
       "      <td>9.45</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15.30</td>\n",
       "      <td>9.15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15.10</td>\n",
       "      <td>9.55</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x1     x2  label\n",
       "0    26.75  22.15      1\n",
       "1    29.80  22.15      1\n",
       "2    31.55  21.10      1\n",
       "3    27.70  20.85      1\n",
       "4    29.90  19.95      1\n",
       "5    26.80  19.05      1\n",
       "6    28.35  18.25      1\n",
       "7    30.40  17.85      1\n",
       "8    27.25  16.70      1\n",
       "9    29.05  16.00      1\n",
       "10   27.15  14.85      1\n",
       "11   28.20  13.95      1\n",
       "12   30.35  13.85      1\n",
       "13   27.25  11.95      1\n",
       "14   29.45  12.05      1\n",
       "15   31.55  12.20      1\n",
       "16   33.05  10.65      1\n",
       "17   29.95   9.85      1\n",
       "18   28.00   9.75      1\n",
       "19   27.15   7.85      1\n",
       "20   29.15   8.10      1\n",
       "21   31.95   8.60      1\n",
       "22   34.70   8.55      1\n",
       "23   34.80  12.25      1\n",
       "24   36.30  15.25      1\n",
       "25   36.60  13.20      1\n",
       "26   38.70  14.25      1\n",
       "27   40.30  15.50      1\n",
       "28   42.25  14.25      1\n",
       "29   40.70  12.80      1\n",
       "..     ...    ...    ...\n",
       "369  20.25   7.05      5\n",
       "370  19.55   7.05      5\n",
       "371  19.05   7.45      5\n",
       "372  18.35   7.60      5\n",
       "373  17.85   7.30      5\n",
       "374  18.30   7.10      5\n",
       "375  18.95   6.85      5\n",
       "376  19.60   6.25      5\n",
       "377  20.15   6.45      5\n",
       "378  18.80   6.25      5\n",
       "379  18.35   6.55      5\n",
       "380  17.65   6.55      5\n",
       "381  17.25   6.90      5\n",
       "382  17.95   6.20      5\n",
       "383  17.45   9.85      6\n",
       "384  17.20   9.25      6\n",
       "385  17.00   9.60      6\n",
       "386  17.00  10.05      6\n",
       "387  16.45  10.10      6\n",
       "388  16.50   9.80      6\n",
       "389  16.60   9.45      6\n",
       "390  16.60   9.05      6\n",
       "391  15.90   9.00      6\n",
       "392  16.05   9.35      6\n",
       "393  16.05   9.65      6\n",
       "394  15.85   9.95      6\n",
       "395  15.35   9.90      6\n",
       "396  15.60   9.45      6\n",
       "397  15.30   9.15      6\n",
       "398  15.10   9.55      6\n",
       "\n",
       "[399 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./compound.csv\",names = [\"x1\", \"x2\", \"label\"])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train.drop(\"label\",axis=1)\n",
    "train_data = train_data.values\n",
    "train_labels = train[\"label\"].values\n",
    "for i in range(len(train_data)):\n",
    "    train_labels[i] = train_labels[i]-1\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 2)\n",
      "(399,)\n"
     ]
    }
   ],
   "source": [
    "tr_data_labels = np.c_[train_data,train_labels]\n",
    "np.random.shuffle(tr_data_labels)\n",
    "tr_data_labels\n",
    "\n",
    "train_labels = tr_data_labels[:,2]\n",
    "train_data = np.delete(tr_data_labels, 2, 1)\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(train_data)\n",
    "dists = [[0 for j in range(N)] for i in range(N)]\n",
    "diag  = [[0 for j in range(N)] for i in range(N)]\n",
    "norms = [[0 for j in range(N)] for i in range(N)]\n",
    "\n",
    "# can improve implementation by using the fact that dists will be symmetric.\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "#         norms[i][j] = np.power(np.linalg.norm(train_data[i]-train_data[j]),2)\n",
    "        dists[i][j] = np.exp(-np.power(np.linalg.norm(train_data[i]-train_data[j]),2))\n",
    "        diag[i][i] += dists[i][j]\n",
    "diag = np.matrix(diag)\n",
    "dists = np.matrix(dists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  5.10560005e-001,  -5.88883694e-275,  -7.97125543e-232, ...,\n",
       "          -1.05159561e-036,  -1.62508391e-210,  -2.84462113e-008],\n",
       "        [ -5.88883694e-275,   3.03153910e-001,  -1.01317822e-004, ...,\n",
       "          -2.52256306e-310,  -2.94775284e-020,  -6.93504831e-296],\n",
       "        [ -7.97125543e-232,  -1.01317822e-004,   9.10032406e-001, ...,\n",
       "          -3.08597500e-253,  -1.46077118e-008,  -8.43421773e-258],\n",
       "        ..., \n",
       "        [ -1.05159561e-036,  -2.52256306e-310,  -3.08597500e-253, ...,\n",
       "           8.48325122e-001,  -1.22654650e-203,  -1.85961564e-075],\n",
       "        [ -1.62508391e-210,  -2.94775284e-020,  -1.46077118e-008, ...,\n",
       "          -1.22654650e-203,   8.52676842e-001,  -3.64383076e-248],\n",
       "        [ -2.84462113e-008,  -6.93504831e-296,  -8.43421773e-258, ...,\n",
       "          -1.85961564e-075,  -3.64383076e-248,   6.21299000e-001]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = diag-dists\n",
    "\n",
    "s = [[0 for j in range(N)] for i in range(N)]\n",
    "for i in range(N):\n",
    "#     s[i][i] = np.power(diag[i,i],-0.5)\n",
    "    s[i][i] = np.sqrt(1/diag[i,i])\n",
    "\n",
    "d1 = np.matrix(s)\n",
    "\n",
    "# for i in range(N):\n",
    "#     s[i][i] = np.power(diag[i,i],0.5)\n",
    "d2 = np.matrix(s)\n",
    "\n",
    "L = np.matmul(np.matmul(d1,tmp),d2)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -4.44170217e-16,   2.19864480e-13,   1.18642348e-05,\n",
       "          1.38469016e-03,   1.97906421e-03,   2.15717342e-03,\n",
       "          2.38205475e-03,   3.65071329e-03,   4.90658900e-03,\n",
       "          4.96999456e-03,   7.13862202e-03,   7.50962523e-03,\n",
       "          7.61680206e-03,   9.98035595e-03,   1.17945805e-02,\n",
       "          1.30299815e-02,   1.46355976e-02,   1.72737728e-02,\n",
       "          1.81768979e-02,   1.83224217e-02,   1.99142124e-02,\n",
       "          2.13761214e-02,   2.27836386e-02,   2.82378260e-02,\n",
       "          2.94279804e-02,   3.17343434e-02,   3.19124377e-02,\n",
       "          3.27660252e-02,   3.48672623e-02,   3.57750921e-02,\n",
       "          3.64341408e-02,   3.96419751e-02,   4.14765602e-02,\n",
       "          4.36532794e-02,   4.43458839e-02,   5.98580912e-02,\n",
       "          6.13863708e-02,   6.37850765e-02,   6.43165572e-02,\n",
       "          7.15526472e-02,   7.15969968e-02,   7.18854006e-02,\n",
       "          7.49698063e-02,   7.78982068e-02,   7.91459726e-02,\n",
       "          8.19090903e-02,   8.31622206e-02,   8.63281791e-02,\n",
       "          8.75666306e-02,   9.05033854e-02,   9.61450654e-02,\n",
       "          9.92238782e-02,   1.03045992e-01,   1.09597936e-01,\n",
       "          1.13472547e-01,   1.19804716e-01,   1.24114228e-01,\n",
       "          1.27033380e-01,   1.28363651e-01,   1.34169995e-01,\n",
       "          1.43411076e-01,   1.47787958e-01,   1.47964059e-01,\n",
       "          1.51995964e-01,   1.57401879e-01,   1.65022626e-01,\n",
       "          1.71035253e-01,   1.74490769e-01,   2.04640339e-01,\n",
       "          2.09964468e-01,   2.13904296e-01,   2.15482889e-01,\n",
       "          2.20301132e-01,   2.35341774e-01,   2.40834132e-01,\n",
       "          2.48163248e-01,   2.55671863e-01,   2.56233803e-01,\n",
       "          2.60278949e-01,   2.63556973e-01,   2.72187516e-01,\n",
       "          2.82259146e-01,   2.84320321e-01,   2.87723756e-01,\n",
       "          2.95697103e-01,   3.08304450e-01,   3.12305816e-01,\n",
       "          3.20677642e-01,   3.25036224e-01,   3.29691258e-01,\n",
       "          3.37385503e-01,   3.43493533e-01,   3.59793829e-01,\n",
       "          3.65644873e-01,   3.65841186e-01,   3.77787399e-01,\n",
       "          3.79845328e-01,   3.81835288e-01,   3.90520606e-01,\n",
       "          4.01541800e-01,   4.14634981e-01,   4.25948955e-01,\n",
       "          4.32879197e-01,   4.36091180e-01,   4.37910569e-01,\n",
       "          4.41738030e-01,   4.47733025e-01,   4.52746162e-01,\n",
       "          4.55422419e-01,   4.72990431e-01,   4.78175304e-01,\n",
       "          4.81514927e-01,   4.90538524e-01,   5.08541189e-01,\n",
       "          5.10120654e-01,   5.26506708e-01,   5.30892893e-01,\n",
       "          5.31805502e-01,   5.33040047e-01,   5.42054652e-01,\n",
       "          5.47963826e-01,   5.56723086e-01,   5.63783590e-01,\n",
       "          5.75248120e-01,   5.77702906e-01,   5.77708995e-01,\n",
       "          5.98262594e-01,   6.06928510e-01,   6.12436821e-01,\n",
       "          6.28022510e-01,   6.28216606e-01,   6.32491145e-01,\n",
       "          6.38211847e-01,   6.46748886e-01,   6.52662527e-01,\n",
       "          6.52843999e-01,   6.54232202e-01,   6.57439341e-01,\n",
       "          6.80782107e-01,   6.85731339e-01,   6.89818359e-01,\n",
       "          6.93913762e-01,   7.05065541e-01,   7.05445619e-01,\n",
       "          7.06732830e-01,   7.14146342e-01,   7.23535879e-01,\n",
       "          7.25482619e-01,   7.28897716e-01,   7.35838527e-01,\n",
       "          7.46765954e-01,   7.47218220e-01,   7.52187710e-01,\n",
       "          7.56201823e-01,   7.61499091e-01,   7.65547290e-01,\n",
       "          7.73038368e-01,   7.73868288e-01,   7.80086107e-01,\n",
       "          7.84249447e-01,   7.85131338e-01,   7.87781429e-01,\n",
       "          7.88450900e-01,   7.90632568e-01,   7.99034938e-01,\n",
       "          8.02698825e-01,   8.07067546e-01,   8.07339447e-01,\n",
       "          8.19000079e-01,   8.19445214e-01,   8.25214643e-01,\n",
       "          8.27867187e-01,   8.35433944e-01,   8.39029975e-01,\n",
       "          8.39093719e-01,   8.41095512e-01,   8.48453625e-01,\n",
       "          8.49443583e-01,   8.53977498e-01,   8.56455882e-01,\n",
       "          8.56538261e-01,   8.58111359e-01,   8.68064788e-01,\n",
       "          8.70025385e-01,   8.73257246e-01,   8.73935452e-01,\n",
       "          8.75167681e-01,   8.76657224e-01,   8.80997946e-01,\n",
       "          8.82726804e-01,   8.88129740e-01,   8.96087743e-01,\n",
       "          8.98112404e-01,   8.98745430e-01,   9.00310744e-01,\n",
       "          9.01776043e-01,   9.03069859e-01,   9.04975354e-01,\n",
       "          9.09743706e-01,   9.11228293e-01,   9.12260803e-01,\n",
       "          9.14105272e-01,   9.17415535e-01,   9.19323252e-01,\n",
       "          9.19611107e-01,   9.20795262e-01,   9.21488003e-01,\n",
       "          9.25114939e-01,   9.28002598e-01,   9.29589676e-01,\n",
       "          9.30936969e-01,   9.32714535e-01,   9.35564585e-01,\n",
       "          9.36770227e-01,   9.37143458e-01,   9.38331950e-01,\n",
       "          9.41210246e-01,   9.44602230e-01,   9.45083646e-01,\n",
       "          9.47183192e-01,   9.48063955e-01,   9.49389234e-01,\n",
       "          9.49810056e-01,   9.51000138e-01,   9.52194080e-01,\n",
       "          9.53674320e-01,   9.54266385e-01,   9.54485996e-01,\n",
       "          9.57122559e-01,   9.57838974e-01,   9.59317739e-01,\n",
       "          9.60534992e-01,   9.60995961e-01,   9.63260162e-01,\n",
       "          9.63468024e-01,   9.63795558e-01,   9.64411317e-01,\n",
       "          9.65024964e-01,   9.66901940e-01,   9.67490442e-01,\n",
       "          9.68792230e-01,   9.68864567e-01,   9.69860084e-01,\n",
       "          9.70134924e-01,   9.70475216e-01,   9.71030423e-01,\n",
       "          9.71765570e-01,   9.72680164e-01,   9.73297218e-01,\n",
       "          9.73591126e-01,   9.75334404e-01,   9.76205281e-01,\n",
       "          9.76356430e-01,   9.76377962e-01,   9.77493582e-01,\n",
       "          9.78193048e-01,   9.78952891e-01,   9.79543443e-01,\n",
       "          9.80192812e-01,   9.80541330e-01,   9.81669539e-01,\n",
       "          9.81746830e-01,   9.81898632e-01,   9.82591447e-01,\n",
       "          9.82982838e-01,   9.83391759e-01,   9.83667680e-01,\n",
       "          9.84297604e-01,   9.84436458e-01,   9.85033424e-01,\n",
       "          9.85187929e-01,   9.85568401e-01,   9.85775287e-01,\n",
       "          9.86101935e-01,   9.86259008e-01,   9.87242597e-01,\n",
       "          9.87532445e-01,   9.87882610e-01,   9.88017840e-01,\n",
       "          9.88250296e-01,   9.88846178e-01,   9.89046388e-01,\n",
       "          9.89202583e-01,   9.89476466e-01,   9.89745403e-01,\n",
       "          9.89968756e-01,   9.90289359e-01,   9.90319971e-01,\n",
       "          9.90604653e-01,   9.90623489e-01,   9.91404063e-01,\n",
       "          9.91483529e-01,   9.91619694e-01,   9.92742888e-01,\n",
       "          9.92845607e-01,   9.93139100e-01,   9.93227480e-01,\n",
       "          9.93264872e-01,   9.93509597e-01,   9.93703737e-01,\n",
       "          9.93753361e-01,   9.93791766e-01,   9.94084448e-01,\n",
       "          9.94170624e-01,   9.94236883e-01,   9.94283893e-01,\n",
       "          9.94451059e-01,   9.94643246e-01,   9.94648650e-01,\n",
       "          9.94810290e-01,   9.95248480e-01,   9.95253710e-01,\n",
       "          9.95417354e-01,   9.95444413e-01,   9.95483975e-01,\n",
       "          9.95874079e-01,   9.95957047e-01,   9.96242125e-01,\n",
       "          9.96348993e-01,   9.96625183e-01,   9.96626655e-01,\n",
       "          9.96730293e-01,   9.96750903e-01,   9.96930862e-01,\n",
       "          9.97173994e-01,   9.97252865e-01,   9.97276523e-01,\n",
       "          9.97290852e-01,   9.97432292e-01,   9.97464856e-01,\n",
       "          9.97486790e-01,   9.97534826e-01,   9.97649497e-01,\n",
       "          9.97695867e-01,   9.97804072e-01,   9.97898829e-01,\n",
       "          9.97971223e-01,   9.98038724e-01,   9.98120710e-01,\n",
       "          9.98181769e-01,   9.98277018e-01,   9.98388118e-01,\n",
       "          9.98429576e-01,   9.98432141e-01,   9.98474032e-01,\n",
       "          9.98487989e-01,   9.98581060e-01,   9.98634259e-01,\n",
       "          9.98657517e-01,   9.98716093e-01,   9.98743601e-01,\n",
       "          9.98786256e-01,   9.98830905e-01,   9.98896581e-01,\n",
       "          9.98898071e-01,   9.98981952e-01,   9.98984647e-01,\n",
       "          9.99065462e-01,   9.99101382e-01,   9.99136792e-01,\n",
       "          9.99267578e-01,   9.99307374e-01,   9.99307776e-01,\n",
       "          9.99345339e-01,   9.99355946e-01,   9.99432942e-01,\n",
       "          9.99437756e-01,   9.99440600e-01,   9.99483870e-01,\n",
       "          9.99508479e-01,   9.99524762e-01,   9.99574356e-01,\n",
       "          9.99589402e-01,   9.99605247e-01,   9.99662295e-01,\n",
       "          9.99670693e-01,   9.99683940e-01,   9.99700369e-01,\n",
       "          9.99724858e-01,   9.99740681e-01,   9.99746946e-01,\n",
       "          9.99749301e-01,   9.99759674e-01,   9.99832790e-01,\n",
       "          9.99841688e-01,   9.99849069e-01,   9.99856393e-01,\n",
       "          9.99861891e-01,   9.99864545e-01,   9.99908384e-01,\n",
       "          9.99911966e-01,   9.99933184e-01,   9.99935589e-01,\n",
       "          9.99949024e-01,   9.99957692e-01,   9.99961480e-01,\n",
       "          9.99962742e-01,   9.99968025e-01,   9.99984214e-01]),\n",
       " array([[ -2.96955808e-02,  -2.22190126e-02,  -7.58529724e-02, ...,\n",
       "           1.29894467e-17,   3.52416442e-17,  -1.78815782e-16],\n",
       "        [ -2.47412954e-02,   3.30665946e-02,   7.46904039e-10, ...,\n",
       "           2.77577925e-04,   2.76534016e-04,   2.18294325e-04],\n",
       "        [ -6.88569554e-02,   9.20269126e-02,   2.07866241e-09, ...,\n",
       "           1.19054677e-01,   8.28743078e-02,  -1.47487907e-01],\n",
       "        ..., \n",
       "        [ -5.33438951e-02,  -3.99133055e-02,   3.26590559e-02, ...,\n",
       "           5.65208010e-14,  -7.24084760e-14,  -3.64662998e-14],\n",
       "        [ -5.38090542e-02,   7.19154819e-02,   1.62398453e-09, ...,\n",
       "          -5.77295611e-02,   2.61495493e-02,   9.01412705e-03],\n",
       "        [ -3.37592917e-02,  -2.52595876e-02,  -8.62716491e-02, ...,\n",
       "           4.16333634e-16,   2.91433544e-16,   3.05311332e-16]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigen_vals, eigen_vecs = eigh(L)\n",
    "eigen_vals, eigen_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.96955808e-02  -2.22190126e-02  -7.58529724e-02]\n",
      " [ -2.47412954e-02   3.30665946e-02   7.46904039e-10]\n",
      " [ -6.88569554e-02   9.20269126e-02   2.07866241e-09]\n",
      " ..., \n",
      " [ -5.33438951e-02  -3.99133055e-02   3.26590559e-02]\n",
      " [ -5.38090542e-02   7.19154819e-02   1.62398453e-09]\n",
      " [ -3.37592917e-02  -2.52595876e-02  -8.62716491e-02]]\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "# V = eigen_vecs[:,N-k:]\n",
    "V = eigen_vecs[:,:k]\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(train_data, train_labels, eps_dis = 1, d = 2, k = 6):\n",
    "    # initialize means to 10 random points\n",
    "    N = len(train_data)\n",
    "    means_indices = np.random.randint(low=0,high=len(train_data),size=k)\n",
    "    #means_indices = [36,31,28,24,21,19,18,26,34,30]\n",
    "    means_new = np.zeros((k,d))\n",
    "    means_old = np.array([train_data[i] for i in means_indices])\n",
    "    eps_dist = eps_dis\n",
    "    diff = means_new-means_old\n",
    "    lst = []\n",
    "    for i in range(k):\n",
    "        lst.append(np.linalg.norm(diff[i]))\n",
    "    dist = np.max(np.array(lst))\n",
    "#     dist = np.linalg.norm(means_new-means_old)\n",
    "    #dist = 100\n",
    "    #dist2 = 0\n",
    "\n",
    "    classes = []\n",
    "    mean_dists = [[0 for i in range(len(train_data))] for j in range(k)]\n",
    "    pbar = tqdm(total = 200+1)\n",
    "\n",
    "    cntr = 0\n",
    "    while dist >= eps_dist:\n",
    "        cntr += 1\n",
    "        b = np.zeros((k,len(train_data)))\n",
    "        mean_dists = [[0 for i in range(len(train_data))] for j in range(k)]\n",
    "\n",
    "        for i in range(k):\n",
    "            for j in range(len(train_data)):\n",
    "                mean_dists[i][j] = np.linalg.norm(train_data[j]-means_old[i])\n",
    "        mean_dists = np.array(mean_dists)\n",
    "\n",
    "        for j in range(len(train_data)):\n",
    "            b[np.argmin(mean_dists[:,j])][j] = 1\n",
    "\n",
    "        b_sum = np.sum(b,axis=1)\n",
    "\n",
    "        for i in range(k):\n",
    "            for j in range(len(train_data)):\n",
    "                means_new[i] = np.add(means_new[i],b[i][j]*train_data[j])\n",
    "            means_new[i] = np.divide(means_new[i],b_sum[i])\n",
    "\n",
    "        #dist = np.linalg.norm(means_new-means_old)\n",
    "        diff = means_new-means_old\n",
    "        lst = []\n",
    "        for i in range(k):\n",
    "            lst.append(np.linalg.norm(diff[i]))\n",
    "        dist = np.max(np.array(lst))\n",
    "        means_old = means_new\n",
    "        means_new =  np.zeros((k,d))\n",
    "        pbar.update(1)\n",
    "        print(\"Iter %d: dist = \" %(cntr),dist)#eps_dist,np.count_nonzero(means_old))\n",
    "\n",
    "    #print(dist,eps_dist)\n",
    "    # finding diameters of clusters\n",
    "    diams = [0 for i in range(k)]\n",
    "    b = np.zeros((k,len(train_data)))\n",
    "    for i in range(k):\n",
    "            for j in range(len(train_data)):\n",
    "                mean_dists[i][j] = np.linalg.norm(train_data[j]-means_old[i])\n",
    "    mean_dists = np.array(mean_dists)\n",
    "\n",
    "    for j in range(len(train_data)):\n",
    "            b[np.argmin(mean_dists[:,j])][j] = 1\n",
    "    for i in range(k):\n",
    "        for j in range(N):\n",
    "            for l in range(N):\n",
    "                if b[i][j] == 1 and b[i][l] == 1:\n",
    "                    t = np.linalg.norm(train_data[j]-train_data[l])\n",
    "                    if diams[i] < t:\n",
    "                        diams[i] = t\n",
    "                \n",
    "    \n",
    "    # predicting labels\n",
    "    final_labels = [0 for i in range(N)]\n",
    "    for j in range(N):\n",
    "        tmp = np.inf\n",
    "        lbl = -1\n",
    "        for i in range(k):\n",
    "            dis = np.linalg.norm(train_data[j]-means_old[i])\n",
    "            if dis < tmp:\n",
    "                tmp = dis\n",
    "                lbl = i\n",
    "        final_labels[j] = lbl\n",
    "    print(\"means: \",means_old)\n",
    "    val = [0 for i in range(k)]\n",
    "    for i in range(N):\n",
    "                val[int(final_labels[i])] += np.power(np.linalg.norm(train_data[i]-means_old[final_labels[i]]),2)\n",
    "\n",
    "    print(\"\\nsq_dists: \",val)\n",
    "    print(\"\\ntotal sq_dists: \", sum(val))\n",
    "    print(\"\\ndiameters: \",diams)\n",
    "    return nmi_score(train_labels, final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f850da6c4aa422c945baf818ba71bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1: dist =  0.0272224074862\n",
      "Iter 2: dist =  0.000301885343177\n",
      "means:  [[ -5.26711208e-02   7.03946406e-02   1.59018207e-09]\n",
      " [ -6.45457019e-02   8.62649479e-02   1.94856389e-09]\n",
      " [ -2.15925924e-02   2.88583717e-02   6.19862141e-10]\n",
      " [ -3.67546347e-02  -2.75007819e-02  -9.36901136e-02]\n",
      " [ -5.76130953e-02  -4.31076333e-02   3.52510200e-02]\n",
      " [ -4.87376382e-02  -3.64667828e-02   2.98270630e-02]]\n",
      "\n",
      "sq_dists:  [0.001252806124122302, 0.0014712751864703886, 0.00014183641842057835, 0.09654280259346365, 0.0020426243993674109, 0.0013182965800951948]\n",
      "\n",
      "total sq_dists:  0.102769641302\n",
      "\n",
      "diameters:  [0.023029955492809766, 0.017510384819188533, 0.0073688935524626673, 0.10804512438134342, 0.01730340104533757, 0.015367617475022414]\n",
      "\n",
      "\n",
      "K = nmi:  0.783249358315\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "print(\"K = 3\")\n",
    "V = eigen_vecs[:,:K]\n",
    "nmi = k_means(train_data = V, train_labels=train_labels, eps_dis = 0.001, k = 6, d = K)\n",
    "print(\"\\nK = nmi: \",nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546d735029554e92a819bf2082897a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1: dist =  0.0829104536\n",
      "Iter 2: dist =  0.132244405797\n",
      "Iter 3: dist =  0.0244969669973\n",
      "Iter 4: dist =  0.0168769782915\n",
      "Iter 5: dist =  0.00162136186308\n",
      "Iter 6: dist =  0.00117934389473\n",
      "Iter 7: dist =  0.000307755808341\n",
      "Iter 8: dist =  0.0\n",
      "means:  [[ -3.67546347e-02  -2.75007819e-02  -9.36901136e-02  -2.99889143e-12\n",
      "   -8.94821580e-12]\n",
      " [ -5.42465426e-02  -4.05886900e-02   3.31936570e-02   1.78137752e-14\n",
      "   -3.68683746e-13]\n",
      " [ -2.18308881e-02   2.91768524e-02   6.13260422e-10  -5.79021114e-03\n",
      "    1.63182102e-02]\n",
      " [ -2.10365691e-02   2.81152499e-02   6.35266152e-10  -1.99641404e-01\n",
      "    1.36328464e-01]\n",
      " [ -6.45457019e-02   8.62649479e-02   1.94856389e-09   1.30282426e-02\n",
      "   -1.06154772e-02]\n",
      " [ -5.26711208e-02   7.03946406e-02   1.59018207e-09   1.02446775e-02\n",
      "   -8.73325307e-03]]\n",
      "\n",
      "sq_dists:  [0.09654280259346365, 0.0096004576033993597, 0.087231810148753197, 1.0031815515218905, 0.0015377406048018329, 0.0013299389613015051]\n",
      "\n",
      "total sq_dists:  1.19942430143\n",
      "\n",
      "diameters:  [0.10804512438134342, 0.032942619205629908, 0.2033051196974569, 0.66112685743346522, 0.017735198505648593, 0.023331112759201442]\n",
      "\n",
      "\n",
      "nmi:  0.835536909499\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "print(\"K = 5\")\n",
    "# V = eigen_vecs[:,N-K:]\n",
    "V = eigen_vecs[:,:K]\n",
    "nmi = k_means(train_data = V, train_labels=train_labels, eps_dis = 0.0001, k = 6, d = K)\n",
    "print(\"\\nnmi: \",nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d203dd94c744c4ada3e6d853e66804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1: dist =  0.0520229093996\n",
      "Iter 2: dist =  0.117808994843\n",
      "Iter 3: dist =  0.0216136728177\n",
      "Iter 4: dist =  0.0105207838442\n",
      "Iter 5: dist =  0.00474376566362\n",
      "Iter 6: dist =  0.0\n",
      "means:  [[ -2.11895375e-02   2.83196912e-02   5.91938911e-10  -1.06322775e-01\n",
      "    8.56978077e-02   9.28836145e-12  -7.08254993e-02   1.72063993e-02\n",
      "   -2.00228888e-02   7.09021167e-02]\n",
      " [ -2.07051860e-02   2.76723583e-02   6.26943811e-10   5.93020113e-03\n",
      "   -1.06826872e-02  -1.73788577e-11  -1.09337444e-01  -2.06130775e-03\n",
      "    9.77363676e-01   1.68646744e-01]\n",
      " [ -3.58323869e-02  -2.68107318e-02  -9.15330586e-02  -8.18623968e-12\n",
      "   -9.14225444e-11  -1.16076318e-01   1.56326940e-11  -5.25547692e-12\n",
      "   -1.09406209e-11   6.10391216e-11]\n",
      " [ -5.32769829e-02   7.12043717e-02   1.60646829e-09   8.76183363e-03\n",
      "   -6.86817391e-03  -8.80874416e-12   6.45576671e-03  -1.22436638e-03\n",
      "   -1.10320040e-03  -4.67442404e-03]\n",
      " [ -3.74964428e-02  -2.80558221e-02  -9.54251362e-02   1.17354086e-12\n",
      "    5.73898311e-11   8.93231176e-02  -1.47965093e-11   9.98990508e-12\n",
      "    3.03659405e-11  -1.72001369e-10]\n",
      " [ -5.42465426e-02  -4.05886900e-02   3.31936570e-02   1.78137752e-14\n",
      "   -3.68683746e-13  -5.75786249e-05   2.38899561e-14   3.67387092e-14\n",
      "   -1.84776438e-14   1.01343872e-13]]\n",
      "\n",
      "sq_dists:  [4.0347644332348747, 0.0, 0.11311876914553903, 0.17263917916226923, 0.11748036643051497, 0.0096005244520800791]\n",
      "\n",
      "total sq_dists:  4.44760327243\n",
      "\n",
      "diameters:  [1.0968730342493598, 0, 0.17613998338384598, 0.1712384674809318, 0.18616709545695959, 0.0329426399530654]\n",
      "\n",
      "\n",
      "nmi:  0.871439110066\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "print(\"K = 10\")\n",
    "# V = eigen_vecs[:,N-K:]\n",
    "V = eigen_vecs[:,:K]\n",
    "nmi = k_means(train_data = V, train_labels=train_labels, eps_dis = 0.0002, k = 6, d = K)\n",
    "print(\"\\nnmi: \",nmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that NMI improves with K (there may be fluctuations due to random initializations).\n",
    "#### Note: Sometimes nan is encountered. Just rerun that cell in that case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
